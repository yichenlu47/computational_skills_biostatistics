---
title: "Homework 7"
subtitle: "BIOST 561: Computational Skills for Biostatistics I"
author: "Students: Yichen Lu & Sirui Liu"
date: "Spring 2020"
urlcolor: blue
output: pdf_document
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE)
```

Submit your solutions via Canvas before 6:00pm on Wednesday May 27 2020.  Work in groups of two or three people to prepare your solutions.  Note that on Canvas there are some initial groups, called 'Homework 7 Groups,' but you should feel free to modify these if you prefer another group configuration.   

## Format for solutions

Submit your solutions as a pdf prepared using [RMarkdown](https://rmarkdown.rstudio.com/).  The source .Rmd file for this pdf is available on Canvas in case you want to use it as the basis for your solutions. 

*Please make sure to submit a well-formatted report.  For example, clearly separate questions from answers, and add your names as the authors of the document!*


## Problem 1

In this problem we will use an example to show that in R we should avoid growing objects inside loops and that we should try to use vectorized operations when possible.  

Consider an autoregresive process of order 1, denoted AR(1), defined by the equation
\[X_t = a + bX_{t-1} + \epsilon_t, ~~ t=2,\dots,T\]
where $X_t$ is the value of the process at time $t$, $\epsilon_t$ is independent white noise, for example $\epsilon_t\sim N(0,\sigma^2)$.  

As you can imagine, the sequencial dependence makes it difficult to avoid `for` loops in generating data from this process.  Nevertheless, there are certain steps that we can take to make our code run efficiently. 

Let's consider different coding options for obtaining sequences of draws from this process:

```{r}
## First, set some parameters that will be used across all approaches
T <- 10000 # length of the process
X1 <- 0 # first value of the process
a <- 0; b <- 0.9 # parameters that determine the process
sigma <- .1 # s.d. of normal white noise


## Approach A: iteratively grow object with results
XA <- X1 
#  we will grow XA to a vector containing all the draws: 
#  note that while we start XA as a scalar, R is quite permissive
#  and it allows us to grow this object iteratively
for (i in 2:T) XA[i] <- a + b*XA[i-1] + rnorm(1,0,sigma)


## Approach B: pre-allocate object that will contain results
XB <- rep(NA, T)
XB[1] <- X1
#  here XB is created with its expected length
#  thereby pre-allocating the memory that will be needed 
for (i in 2:T) XB[i] <- a + b*XB[i-1] + rnorm(1,0,sigma)


## Approach C: pre-allocate and vectorize generation of noise
XC <- rep(NA, T)
XC[1] <- X1
noise <- rnorm(T,0,sigma) # all noise terms generated at once
for (i in 2:T) XC[i] <- a + b*XC[i-1] + noise[i]
```

Your goal for this problem is to:

- Use the `microbenchmark` package to compare the efficiency of these approaches

- Explain why approach C is more efficient than B, and why B is more efficient than A

### Solution

```{r,eval=TRUE}

# Rename the approaches 
approachA<-function(){
  XA <- X1 
#  we will grow XA to a vector containing all the draws: 
#  note that while we start XA as a scalar, R is quite permissive
#  and it allows us to grow this object iteratively
for (i in 2:T) XA[i] <- a + b*XA[i-1] + rnorm(1,0,sigma)
}

approachB<-function(){
  XB <- rep(NA, T)
XB[1] <- X1
#  here XB is created with its expected length
#  thereby pre-allocating the memory that will be needed 
for (i in 2:T) XB[i] <- a + b*XB[i-1] + rnorm(1,0,sigma)
}

approachC<-function(){
  XC <- rep(NA, T)
XC[1] <- X1
noise <- rnorm(T,0,sigma) # all noise terms generated at once
for (i in 2:T) XC[i] <- a + b*XC[i-1] + noise[i]
}


# microbenchmarking
library(microbenchmark)
set.seed(666)
ntimes <- 100L
results <-microbenchmark(approachA(),
                         approachB(),
                         approachC(),
                         times = ntimes)
summ_res <-summary(results)
summ_res

```

#### Comments:

Since approach C only generates noise once, and approach B generates noise in each loop(T-2) times, C is more efficient than B. Compared to approach B, approach A also needs to grow the vector iteratively, while in approach B the vector Xt has the assigned length initially. Therefore, approach B is more efficient than approach A. 


## Problem 2

In this problem we will explore `for` loops vs `apply` vs vectorized operations.

Consider the following matrix `mm`
```{r}
mm <- rnorm(200*2)
dim(mm) <- c(200,2) # remember: a matrix is an atomic vector with attribute 'dim' of length 2
```
Consider the following approaches to obtain the sums of the rows of this matrix:
```{r}
# Approach A
rsumsA <- rep(NA,200)
for (i in 1:200) rsumsA[i] <- sum(mm[i,])
# Approach B
rsumsB <- apply(mm,1,sum)
# Approach C
rsumsC <- rowSums(mm)
# Approach D 
rsumsD <- mm[,1]+mm[,2]

# Do they produce the same result?
identical(rsumsA,rsumsB)
identical(rsumsB,rsumsC)
identical(rsumsC,rsumsD)
# yes
```
Your goal in this problem is to 

- Use the `microbenchmark` library to compare the approaches A -- D above

- Comment on why A is slower than B, B is slower than C, and C is slower than D

### Solution

```{r,eval=TRUE}
# Approach A

ntimes <-1000L
rsums_results <-microbenchmark(app_A<-for (i in 1:200) rsumsA[i] <- sum(mm[i,]),
                        app_B <- apply(mm,1,sum),
                         app_C <- rowSums(mm),
                        app_D <- mm[,1]+mm[,2],
                         times = ntimes)
rsums_results_table <-summary(rsums_results)
rsums_results_table

```

#### Comments:
Approach A used a for loop to sum each row in the matrix. While it processed the sum function, a matrix would grow iteratively. However, apply() doesn't need to grow the matrix iteratively because its output only depends on its input. In this case, the input is mm. Therefore, approach A is slower than approach B. Approach B is slower than approach C because approach B needs to call apply() and then call sum(),while rowSums() is a optimised function that was built in R. So approac B is slower than approach C. Approach D is the most direct way to sum the rows because it's given that mm is already a matrix and it assumes that their are only 2 columns in the matrix, while approach C has to verify if mm is a matrix at first and has to check how many elements are in the matrix. So approach C is slower than approach D, but approach D can be only applied in the case that the input is known and the number of columns of the matrix is known. 



## Problem 3

In this problem we will go over the example that we couldn't cover in class that implements  K-fold cross validation in parallel.  

Your goal for this problem is 

- Figure out how many logical processors you have available in your computer

- Go over the code below, modifying it so that it uses the number of logical processors in your computer, and report your results

### Solution

Number of logical processors available:
```{r, eval=TRUE}
library(parallel)
detectCores()
```

Parallel coding helps decrease the time to complete the cross-validation task. The code is modified to use the number of logical processors in my computer.
```{r, eval=TRUE}
# A mixture of normals to be used for logistic regression
n1 <- 50000
n0 <- 40000
library(MASS)
Sigma <- diag(50) # identity matrix of size 50
Sigma[1:3,1:3] <- matrix(c(10,3,0,3,2,0,0,0,10),3,3)
Sigma[7:9,7:9] <- matrix(c(10,3,0,3,2,0,0,0,10),3,3)
mydata <- rbind(data.frame(Y=0,X=mvrnorm(n0,rep(0,50),Sigma)), 
                data.frame(Y=1,X=mvrnorm(n1,c(rnorm(10),rep(0,40)),Sigma))) 
head(mydata)

# fitting a logistic regression with all the data
system.time(
	model <- glm(Y ~ ., family=binomial(link='logit'), data=mydata)
)
# check in-sample performance
in_sample_probs <- predict(model, newdata=mydata, type='response')

# assuming both types of errors are equally bad, the Bayes classifier is optimal
in_sample_pred <- 1*(in_sample_probs > 0.5)

# confusion matrix 
confmat <- table(truth=mydata$Y, guess=in_sample_pred)

# accuracy 
sum(diag(confmat))/sum(confmat)



# K-fold CV:
#  - split your data into K folds
#  - leave one fold out as test data, train on remainder K-1
#  - repeat for each fold
#  - compute measures of accuracy for each fold, and average

# Say K=10
folds <- sample(1:10, nrow(mydata), replace=TRUE)

# Let's
#  - Implement 10-fold CV in R without parallelizing
#  - Implement a parallelized version of 10-fold CV 

# To start, how would we do this for one single fold?

# Let's create a function that takes the fold number and does what we need

foldCV_logistic <- function(curr_fold, mydata, folds){
   
  # fitting a logistic regression with K-1 folds
  model <- glm(Y ~ ., family=binomial(link='logit'), data=mydata[folds!=curr_fold,])
  
  # predict on fold that was reserved for  testing
  pred_probs <- predict(model, newdata=mydata[folds==curr_fold,], type='response')
  
  # assuming both types of errors are equally bad, the Bayes classifier is optimal
  pred_labels <- 1*(pred_probs > 0.5 )
   
  # confusion matrix  
  confmat <- table(truth=mydata$Y[folds==curr_fold], guess=pred_labels)
   
  # accuracy  
  fold_accu <- sum(diag(confmat))/sum(confmat)
  
  return(fold_accu)
}

# Let's leave out the first fold
foldCV_logistic(curr_fold=1, mydata, folds) 

# Now we just need to apply the function to the vector 1:10
sequential_time <- system.time(
    all_accu <- sapply(1:10, foldCV_logistic, mydata=mydata, folds=folds)
  )


# save the number of logical processors in my computer 
nnn <- detectCores()

# Let's do it in parallel
library(snow)
# uses the number of logical processors in my computer
cl <- makeCluster(nnn, type="SOCK")
parallel_time <- snow.time(
    all_accu_para <- parSapply(cl, 1:10, foldCV_logistic, mydata=mydata, folds=folds)
)
stopCluster(cl)


# compare times
sequential_time[3]
# vs
parallel_time[1]
# Reasonable savings?

plot(parallel_time) # Gantt chart: it seems not too much communication cost here
```

